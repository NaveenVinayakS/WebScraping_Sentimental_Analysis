{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "popular-mambo",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "import matplotlib.patches as mpatches\n",
    "import time\n",
    "\n",
    "# Classifier Libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import collections\n",
    "\n",
    "\n",
    "# Other Libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"scraping.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "involved-appeal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Rating</th>\n",
       "      <th>r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From last 5 years my younger brother was using...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>excellent phone camera is very nice and the st...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have been using the earlier versions of iPho...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMPORTANT NOTICEIf you buy some apple device o...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Well, what can I say... iPhone is awesome as e...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  Rating  r\n",
       "0  From last 5 years my younger brother was using...       5  1\n",
       "1  excellent phone camera is very nice and the st...       4  1\n",
       "2  I have been using the earlier versions of iPho...       4  1\n",
       "3  IMPORTANT NOTICEIf you buy some apple device o...       5  1\n",
       "4  Well, what can I say... iPhone is awesome as e...       5  1"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "extended-lying",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(827, 3)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "proud-median",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    774\n",
       "0     53\n",
       "Name: r, dtype: int64"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['r'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "attended-shannon",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_data,x_test_data,Y_train_data,y_test_data = train_test_split(df[\"Comment\"],df[\"r\"],test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "shared-raleigh",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "prescribed-quebec",
   "metadata": {},
   "source": [
    "# Data Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "allied-morning",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "tfidf_vector = TfidfVectorizer(stop_words=\"english\")\n",
    "tfidf_vector.fit(X_train_data)\n",
    "X_train_data_new=tfidf_vector.transform(X_train_data)\n",
    "x_test_data_new=tfidf_vector.transform(x_test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "governmental-detroit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(166, 2166)\n",
      "(661, 2166)\n"
     ]
    }
   ],
   "source": [
    "print(x_test_data_new.shape)\n",
    "print(X_train_data_new.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welcome-reservation",
   "metadata": {},
   "source": [
    "# Smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "injured-timeline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After OverSampling, the shape of train_X: (661, 2166)\n",
      "After OverSampling, the shape of train_y: (1240,) \n",
      "\n",
      "Before OverSampling, counts of label '1': 617\n",
      "Before OverSampling, counts of label '0': 44 \n",
      "\n",
      "After OverSampling, the shape of train_X: (661, 2166)\n",
      "After OverSampling, the shape of train_y: (1234,) \n",
      "\n",
      "After OverSampling, counts of label '1': 617\n",
      "After OverSampling, counts of label '0': 617\n",
      "\n",
      "\n",
      "(661, 2166)\n",
      "res :- (1234, 2166)\n",
      "res :- (1234,)\n",
      "\n",
      "\n",
      "(166, 2166)\n",
      "(166,)\n"
     ]
    }
   ],
   "source": [
    "print('After OverSampling, the shape of train_X: {}'.format(X_train_data_new.shape))\n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape))\n",
    "\n",
    "\n",
    "print(\"Before OverSampling, counts of label '1': {}\".format(sum(Y_train_data == 1)))\n",
    "print(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(Y_train_data == 0)))\n",
    "  \n",
    "# import SMOTE module from imblearn library\n",
    "# pip install imblearn (if you don't have imblearn in your system)\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(sampling_strategy='minority',random_state = 2)\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train_data_new, Y_train_data.ravel())\n",
    "  \n",
    "print('After OverSampling, the shape of train_X: {}'.format(X_train_data_new.shape))\n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape))\n",
    "  \n",
    "print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res == 1)))\n",
    "print(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res == 0)))\n",
    "\n",
    "print('\\n')\n",
    "print(X_train_data_new.shape)\n",
    "print(\"res :-\",X_train_res.shape)\n",
    "print(\"res :-\",y_train_res.shape)\n",
    "print('\\n')\n",
    "print(x_test_data_new.shape)\n",
    "print(y_test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sorted-motor",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "external-adobe",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "departmental-bouquet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9337349397590361"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = dict()\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr_model = LogisticRegression()\n",
    "\n",
    "lr_model.fit(X_train_res,y_train_res)\n",
    "predictions[\"LogisticRegression\"] = lr_model.predict(x_test_data_new)\n",
    "from sklearn.metrics import classification_report,accuracy_score,confusion_matrix\n",
    "accuracy_score(y_test_data,predictions[\"LogisticRegression\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "fabulous-packaging",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisiticRegression \n",
      " LogisticRegression()\n",
      "Classifiers:  LogisticRegression Has a training score of 93.0 % accuracy score\n",
      "KNearest \n",
      " KNeighborsClassifier()\n",
      "Classifiers:  KNeighborsClassifier Has a training score of 92.0 % accuracy score\n",
      "Support Vector Classifier \n",
      " SVC()\n",
      "Classifiers:  SVC Has a training score of 95.0 % accuracy score\n",
      "DecisionTreeClassifier \n",
      " DecisionTreeClassifier()\n",
      "Classifiers:  DecisionTreeClassifier Has a training score of 95.0 % accuracy score\n"
     ]
    }
   ],
   "source": [
    "classifiers = {\n",
    "    \"LogisiticRegression\": LogisticRegression(),\n",
    "    \"KNearest\": KNeighborsClassifier(),\n",
    "    \"Support Vector Classifier\": SVC(),\n",
    "    \"DecisionTreeClassifier\": DecisionTreeClassifier()\n",
    "}\n",
    "\n",
    "# Wow our scores are getting even high scores even when applying cross validation.\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "for key, classifier in classifiers.items():\n",
    "    print(key,'\\n',classifier)\n",
    "    classifier.fit(X_train_res,y_train_res)\n",
    "    training_score = cross_val_score(classifier, X_train_data_new, Y_train_data, cv=5)\n",
    "    print(\"Classifiers: \", classifier.__class__.__name__, \"Has a training score of\", round(training_score.mean(), 2) * 100, \"% accuracy score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "supposed-complaint",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<1234x2166 sparse matrix of type '<class 'numpy.float64'>'\n",
       " \twith 31969 stored elements in Compressed Sparse Row format>,\n",
       " array([1, 1, 1, ..., 0, 0, 0], dtype=int64))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using Grid SearchCV to find the best parameters.\n",
    "\n",
    "# Use GridSearchCV to find the best parameters.\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "# Logistic Regression \n",
    "log_reg_params = {\"penalty\": ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "\n",
    "grid_log_reg = GridSearchCV(LogisticRegression(), log_reg_params,cv=5)\n",
    "grid_log_reg.fit(X_train_res,y_train_res)\n",
    "# We automatically get the logistic regression with the best parameters.\n",
    "log_reg = grid_log_reg.best_estimator_\n",
    "log_reg_param = grid_log_reg.param_grid\n",
    "\n",
    "\n",
    "# KNN Algorithm\n",
    "knears_params = {\"n_neighbors\": list(range(2,5,1)), 'algorithm': ['auto', 'ball_tree', 'kd_tree', 'brute']}\n",
    "\n",
    "grid_knears = GridSearchCV(KNeighborsClassifier(), knears_params,cv=5)\n",
    "grid_knears.fit(X_train_res,y_train_res)\n",
    "# KNears best estimator\n",
    "knears_neighbors = grid_knears.best_estimator_\n",
    "knears_neighbors_param_grid = grid_knears.param_grid\n",
    "\n",
    "\n",
    "# Support Vector Classifier\n",
    "svc_params = {'C': [0.5, 0.7, 0.9, 1], 'kernel': ['rbf', 'poly', 'sigmoid', 'linear']}\n",
    "grid_svc = GridSearchCV(SVC(), svc_params,cv=5)\n",
    "grid_svc.fit(X_train_res,y_train_res)\n",
    "svc = grid_svc.best_estimator_\n",
    "svc_param_grid = grid_svc.param_grid\n",
    "\n",
    "\n",
    "# DecisionTree Classifier\n",
    "tree_params = {\"criterion\": [\"gini\", \"entropy\"], \"max_depth\": list(range(2,4,1)), \n",
    "              \"min_samples_leaf\": list(range(5,7,1))}\n",
    "grid_tree = GridSearchCV(DecisionTreeClassifier(), tree_params,cv=5)\n",
    "grid_tree.fit(X_train_res,y_train_res)\n",
    "tree_clf = grid_tree.best_estimator_\n",
    "tree_clf_param_grid = grid_tree.param_grid\n",
    "\n",
    "X_train_res, y_train_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "identical-sarah",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Cross Validation Score:  99.27%\n",
      "Knears Neighbors Cross Validation Score 75.53%\n",
      "Support Vector Classifier Cross Validation Score 99.68%\n",
      "DecisionTree Classifier Cross Validation Score 87.84%\n"
     ]
    }
   ],
   "source": [
    "# Overfitting Case\n",
    "\n",
    "log_reg_score = cross_val_score(log_reg, X_train_res, y_train_res, cv=5)\n",
    "print('Logistic Regression Cross Validation Score: ', round(log_reg_score.mean() * 100, 2).astype(str) + '%')\n",
    "\n",
    "\n",
    "knears_score = cross_val_score(knears_neighbors, X_train_res, y_train_res, cv=5)\n",
    "print('Knears Neighbors Cross Validation Score', round(knears_score.mean() * 100, 2).astype(str) + '%')\n",
    "\n",
    "svc_score = cross_val_score(svc, X_train_res, y_train_res, cv=5)\n",
    "print('Support Vector Classifier Cross Validation Score', round(svc_score.mean() * 100, 2).astype(str) + '%')\n",
    "\n",
    "tree_score = cross_val_score(tree_clf, X_train_res, y_train_res, cv=5)\n",
    "print('DecisionTree Classifier Cross Validation Score', round(tree_score.mean() * 100, 2).astype(str) + '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "filled-berlin",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "\n",
    "log_reg_pred = cross_val_predict(log_reg, X_train_res, y_train_res, cv=5, method=\"decision_function\")\n",
    "\n",
    "knears_pred = cross_val_predict(knears_neighbors,X_train_res, y_train_res, cv=5)\n",
    "\n",
    "svc_pred = cross_val_predict(svc, X_train_res, y_train_res,cv=5,method=\"decision_function\")\n",
    "\n",
    "tree_pred = cross_val_predict(tree_clf,X_train_res, y_train_res,cv=5)\n",
    "\n",
    "# Logistic Regression fitted using SMOTE technique\n",
    "y_pred_log_reg = log_reg.predict(x_test_data_new)\n",
    "\n",
    "# Other models fitted with UnderSampling\n",
    "y_pred_knear = knears_neighbors.predict(x_test_data_new)\n",
    "y_pred_svc = svc.predict(x_test_data_new)\n",
    "y_pred_tree = tree_clf.predict(x_test_data_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "extensive-player",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg_cf = confusion_matrix(y_test_data, y_pred_log_reg)\n",
    "kneighbors_cf = confusion_matrix(y_test_data, y_pred_knear)\n",
    "svc_cf = confusion_matrix(y_test_data, y_pred_svc)\n",
    "tree_cf = confusion_matrix(y_test_data, y_pred_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "alpine-roommate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.56      0.53         9\n",
      "           1       0.97      0.97      0.97       157\n",
      "\n",
      "    accuracy                           0.95       166\n",
      "   macro avg       0.74      0.76      0.75       166\n",
      "weighted avg       0.95      0.95      0.95       166\n",
      "\n",
      "KNears Neighbors:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      1.00      0.24         9\n",
      "           1       1.00      0.64      0.78       157\n",
      "\n",
      "    accuracy                           0.66       166\n",
      "   macro avg       0.57      0.82      0.51       166\n",
      "weighted avg       0.95      0.66      0.75       166\n",
      "\n",
      "Support Vector Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.44      0.44         9\n",
      "           1       0.97      0.97      0.97       157\n",
      "\n",
      "    accuracy                           0.94       166\n",
      "   macro avg       0.71      0.71      0.71       166\n",
      "weighted avg       0.94      0.94      0.94       166\n",
      "\n",
      "Support Vector Classifier:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.14      0.56      0.23         9\n",
      "           1       0.97      0.81      0.88       157\n",
      "\n",
      "    accuracy                           0.80       166\n",
      "   macro avg       0.56      0.68      0.55       166\n",
      "weighted avg       0.92      0.80      0.85       166\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "print('Logistic Regression:')\n",
    "print(classification_report(y_test_data, y_pred_log_reg))\n",
    "\n",
    "print('KNears Neighbors:')\n",
    "print(classification_report(y_test_data, y_pred_knear))\n",
    "\n",
    "print('Support Vector Classifier:')\n",
    "print(classification_report(y_test_data, y_pred_svc))\n",
    "\n",
    "print('Support Vector Classifier:')\n",
    "print(classification_report(y_test_data, y_pred_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foster-compact",
   "metadata": {},
   "source": [
    "#### Logistic Regression is better accuracy , precision , recall comared with other algorithm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
