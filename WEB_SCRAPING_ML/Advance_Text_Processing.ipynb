{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "important-turkey",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From last 5 years my younger brother was using...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>excellent phone camera is very nice and the st...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have been using the earlier versions of iPho...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMPORTANT NOTICEIf you buy some apple device o...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Well, what can I say... iPhone is awesome as e...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  Rating\n",
       "0  From last 5 years my younger brother was using...       5\n",
       "1  excellent phone camera is very nice and the st...       4\n",
       "2  I have been using the earlier versions of iPho...       4\n",
       "3  IMPORTANT NOTICEIf you buy some apple device o...       5\n",
       "4  Well, what can I say... iPhone is awesome as e...       5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('scraping.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "awful-knife",
   "metadata": {},
   "source": [
    "#### Ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "thick-redhead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[WordList(['From', 'last']),\n",
       " WordList(['last', '5']),\n",
       " WordList(['5', 'years']),\n",
       " WordList(['years', 'my']),\n",
       " WordList(['my', 'younger']),\n",
       " WordList(['younger', 'brother']),\n",
       " WordList(['brother', 'was']),\n",
       " WordList(['was', 'using']),\n",
       " WordList(['using', 'iphone']),\n",
       " WordList(['iphone', '4s']),\n",
       " WordList(['4s', 'and']),\n",
       " WordList(['and', 'i']),\n",
       " WordList(['i', 'bought']),\n",
       " WordList(['bought', 'iphone']),\n",
       " WordList(['iphone', '7']),\n",
       " WordList(['7', 'for']),\n",
       " WordList(['for', 'his']),\n",
       " WordList(['his', 'birthday']),\n",
       " WordList(['birthday', 'gift']),\n",
       " WordList(['gift', 'When']),\n",
       " WordList(['When', 'i']),\n",
       " WordList(['i', 'gave']),\n",
       " WordList(['gave', 'gift']),\n",
       " WordList(['gift', 'packet']),\n",
       " WordList(['packet', 'to']),\n",
       " WordList(['to', 'him']),\n",
       " WordList(['him', 'he']),\n",
       " WordList(['he', 'was']),\n",
       " WordList(['was', 'thinking']),\n",
       " WordList(['thinking', 'that']),\n",
       " WordList(['that', 'my']),\n",
       " WordList(['my', 'bro']),\n",
       " WordList(['bro', 'bought']),\n",
       " WordList(['bought', 'watch/pen/or']),\n",
       " WordList(['watch/pen/or', 'something']),\n",
       " WordList(['something', 'else']),\n",
       " WordList(['else', 'but']),\n",
       " WordList(['but', 'he']),\n",
       " WordList(['he', 'did']),\n",
       " WordList(['did', \"n't\"]),\n",
       " WordList([\"n't\", 'expected']),\n",
       " WordList(['expected', 'iphone']),\n",
       " WordList(['iphone', '7']),\n",
       " WordList(['7', 'When']),\n",
       " WordList(['When', 'he']),\n",
       " WordList(['he', 'opened']),\n",
       " WordList(['opened', 'i']),\n",
       " WordList(['i', 'found']),\n",
       " WordList(['found', 'tear']),\n",
       " WordList(['tear', 'in']),\n",
       " WordList(['in', 'his']),\n",
       " WordList(['his', 'eye']),\n",
       " WordList(['eye', 'and']),\n",
       " WordList(['and', 'he']),\n",
       " WordList(['he', 'hug']),\n",
       " WordList(['hug', 'me.this']),\n",
       " WordList(['me.this', 'all']),\n",
       " WordList(['all', 'possible']),\n",
       " WordList(['possible', 'only']),\n",
       " WordList(['only', 'because']),\n",
       " WordList(['because', 'of']),\n",
       " WordList(['of', 'flipkart']),\n",
       " WordList(['flipkart', 'sale']),\n",
       " WordList(['sale', 'coz']),\n",
       " WordList(['coz', 'we']),\n",
       " WordList(['we', 'r']),\n",
       " WordList(['r', 'from']),\n",
       " WordList(['from', 'middle']),\n",
       " WordList(['middle', 'class']),\n",
       " WordList(['class', 'family']),\n",
       " WordList(['family', 'and']),\n",
       " WordList(['and', 'ca']),\n",
       " WordList(['ca', \"n't\"]),\n",
       " WordList([\"n't\", 'afford']),\n",
       " WordList(['afford', 'this']),\n",
       " WordList(['this', 'mobile']),\n",
       " WordList(['mobile', 'in']),\n",
       " WordList(['in', 'it']),\n",
       " WordList(['it', \"'s\"]),\n",
       " WordList([\"'s\", 'actual']),\n",
       " WordList(['actual', 'price']),\n",
       " WordList(['price', 'so']),\n",
       " WordList(['so', 'flipkart']),\n",
       " WordList(['flipkart', 'makes']),\n",
       " WordList(['makes', 'us']),\n",
       " WordList(['us', 'happy.Thanks']),\n",
       " WordList(['happy.Thanks', 'you']),\n",
       " WordList(['you', 'flipkart']),\n",
       " WordList(['flipkart', 'üòç'])]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "TextBlob(df['Comment'][0]).ngrams(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "revised-waterproof",
   "metadata": {},
   "source": [
    "#### Term frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "frank-combining",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>tf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>for</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cool</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  words  tf\n",
       "0    it   2\n",
       "1   for   2\n",
       "2   the   2\n",
       "3  cool   1\n",
       "4     .   1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf1 = (df['Comment'][1:2]).apply(lambda x: pd.value_counts(x.split(\" \"))).sum(axis = 0).reset_index()\n",
    "tf1.columns = ['words','tf']\n",
    "tf1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conservative-projection",
   "metadata": {},
   "source": [
    "#### Inverse Document Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "julian-daughter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>tf</th>\n",
       "      <th>idf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it</td>\n",
       "      <td>2</td>\n",
       "      <td>0.227081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>for</td>\n",
       "      <td>2</td>\n",
       "      <td>0.527489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>2</td>\n",
       "      <td>0.541937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cool</td>\n",
       "      <td>1</td>\n",
       "      <td>3.385600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  words  tf       idf\n",
       "0    it   2  0.227081\n",
       "1   for   2  0.527489\n",
       "2   the   2  0.541937\n",
       "3  cool   1  3.385600\n",
       "4     .   1  0.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "for i,word in enumerate(tf1['words']):\n",
    "    tf1.loc[i, 'idf'] = np.log(df.shape[0]/(len(df[df['Comment'].str.contains(word)])))\n",
    "tf1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blocked-circle",
   "metadata": {},
   "source": [
    "#### Term Frequency ‚Äì Inverse Document Frequency (TF-IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "social-entrepreneur",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>tf</th>\n",
       "      <th>idf</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>it</td>\n",
       "      <td>2</td>\n",
       "      <td>0.227081</td>\n",
       "      <td>0.454162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>for</td>\n",
       "      <td>2</td>\n",
       "      <td>0.527489</td>\n",
       "      <td>1.054979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>2</td>\n",
       "      <td>0.541937</td>\n",
       "      <td>1.083875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cool</td>\n",
       "      <td>1</td>\n",
       "      <td>3.385600</td>\n",
       "      <td>3.385600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  words  tf       idf     tfidf\n",
       "0    it   2  0.227081  0.454162\n",
       "1   for   2  0.527489  1.054979\n",
       "2   the   2  0.541937  1.083875\n",
       "3  cool   1  3.385600  3.385600\n",
       "4     .   1  0.000000  0.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF-IDF is the multiplication of the TF and IDF which we calculated above.\n",
    "\n",
    "tf1['tfidf'] = tf1['tf'] * tf1['idf']\n",
    "tf1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "paperback-daisy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<827x1000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 17616 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We don‚Äôt have to calculate TF and IDF every time beforehand and then multiply it to obtain TF-IDF. Instead, sklearn has a separate function to directly obtain it:\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(max_features=1000, lowercase=True, analyzer='word',\n",
    " stop_words= 'english',ngram_range=(1,1))\n",
    "train_vect = tfidf.fit_transform(df['Comment'])\n",
    "\n",
    "train_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "missing-speaking",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can also perform basic pre-processing steps like lower-casing and removal of stopwords, if we haven‚Äôt done them earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endless-shore",
   "metadata": {},
   "source": [
    "#### Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "worldwide-environment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<827x1000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 28682 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow = CountVectorizer(max_features=1000, lowercase=True, ngram_range=(1,1),analyzer = \"word\")\n",
    "train_bow = bow.fit_transform(df['Comment'])\n",
    "train_bow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorrect-thompson",
   "metadata": {},
   "source": [
    " #### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welcome-asian",
   "metadata": {},
   "source": [
    "If you recall, our problem was to detect the sentiment of the tweet. So, before applying any ML/DL models (which can have a separate feature detecting the sentiment using the textblob library), let‚Äôs check the sentiment of the first few tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "hollow-messenger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    (-0.014285714285714287, 0.3666666666666667)\n",
       "1                                  (0.506, 0.75)\n",
       "2       (0.1619047619047619, 0.6476190476190476)\n",
       "3       (0.5041666666666667, 0.7305555555555555)\n",
       "4       (0.4055555555555556, 0.5944444444444444)\n",
       "Name: Comment, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Comment'][:5].apply(lambda x: TextBlob(x).sentiment)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "muslim-challenge",
   "metadata": {},
   "source": [
    "Above, you can see that it returns a tuple representing polarity and subjectivity of each tweet. Here, we only extract polarity as it indicates the sentiment as value nearer to 1 means a positive sentiment and values nearer to -1 means a negative sentiment. This can also work as a feature for building a machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "sensitive-purchase",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>From last 5 years my younger brother was using...</td>\n",
       "      <td>-0.014286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>excellent phone camera is very nice and the st...</td>\n",
       "      <td>0.506000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I have been using the earlier versions of iPho...</td>\n",
       "      <td>0.161905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IMPORTANT NOTICEIf you buy some apple device o...</td>\n",
       "      <td>0.504167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Well, what can I say... iPhone is awesome as e...</td>\n",
       "      <td>0.405556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment  sentiment\n",
       "0  From last 5 years my younger brother was using...  -0.014286\n",
       "1  excellent phone camera is very nice and the st...   0.506000\n",
       "2  I have been using the earlier versions of iPho...   0.161905\n",
       "3  IMPORTANT NOTICEIf you buy some apple device o...   0.504167\n",
       "4  Well, what can I say... iPhone is awesome as e...   0.405556"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'] = df['Comment'].apply(lambda x: TextBlob(x).sentiment[0] )\n",
    "df[['Comment','sentiment']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bridal-figure",
   "metadata": {},
   "source": [
    "#### Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "boolean-style",
   "metadata": {},
   "source": [
    "Word Embedding is the representation of text in the form of vectors. The underlying idea here is that similar words will have a minimum distance between their vectors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promising-indication",
   "metadata": {},
   "source": [
    "Word2Vec models require a lot of text, so either we can train it on our training data or we can use the pre-trained word vectors developed by Google, Wiki, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "extended-liabilities",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400000, 100)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "glove_input_file = r'C:\\Users\\z030590\\OneDrive - Alliance\\Desktop\\Personal\\Practice\\WEB_SCRAPING_ML\\glove.6B\\glove.6B.100d.txt'\n",
    "word2vec_output_file = r'C:\\Users\\z030590\\OneDrive - Alliance\\Desktop\\Personal\\Practice\\WEB_SCRAPING_ML\\glove.6B\\glove.6B.100d.txt.word2vec'\n",
    "glove2word2vec(glove_input_file, word2vec_output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technological-module",
   "metadata": {},
   "source": [
    "Now, we can load the above word2vec file as a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "sixth-canadian",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors # load the Stanford GloVe model\n",
    "filename = 'glove.6B.100d.txt.word2vec'\n",
    "model = KeyedVectors.load_word2vec_format(filename, binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "technological-check",
   "metadata": {},
   "source": [
    "Let‚Äôs say our Review contains a text saying ‚ÄòWorst Product‚Äô. We can easily obtain it‚Äôs word vector using the above model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "formed-collar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.10823 ,  0.53741 ,  0.885   , -0.30311 , -0.58348 , -0.19097 ,\n",
       "       -0.33086 , -0.37934 , -0.24386 ,  0.12135 , -0.094278, -0.38937 ,\n",
       "        0.29407 , -0.19807 , -0.13636 ,  0.56784 , -0.2646  , -0.38357 ,\n",
       "       -0.35089 ,  0.86936 ,  0.86949 ,  0.15402 ,  0.28293 ,  0.1179  ,\n",
       "       -0.1568  , -0.66417 , -0.29127 ,  0.48797 ,  0.10922 , -0.40979 ,\n",
       "        0.44929 , -0.4953  ,  0.4276  ,  0.37889 , -0.57139 , -0.59073 ,\n",
       "       -0.34217 , -0.36057 , -0.027326,  0.12269 , -0.65577 ,  0.66994 ,\n",
       "        0.21313 ,  0.013424,  0.98328 ,  1.1144  ,  1.0071  , -0.57594 ,\n",
       "       -0.38352 , -1.0815  , -0.14601 , -0.40779 , -0.30278 ,  0.88406 ,\n",
       "       -0.13341 , -2.0044  ,  0.55541 ,  0.53672 ,  1.4316  ,  0.61509 ,\n",
       "       -0.84024 ,  0.83837 , -0.90179 , -0.52281 ,  0.69407 ,  0.42772 ,\n",
       "        0.26326 , -0.46818 , -0.010143, -0.1348  , -0.1372  ,  0.09444 ,\n",
       "       -0.82502 ,  1.1274  ,  0.23282 ,  0.021967, -0.46332 , -0.020093,\n",
       "       -0.72729 ,  0.49759 ,  0.82981 ,  0.66017 , -0.67841 ,  0.3261  ,\n",
       "       -0.95574 , -0.5538  , -0.82081 , -0.37433 , -0.29929 ,  0.020877,\n",
       "        0.47573 ,  0.74171 , -0.44521 ,  0.041126, -0.55041 ,  0.54808 ,\n",
       "        0.19292 ,  0.24759 ,  0.21934 , -0.33977 ], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['worst']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "exempt-signal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.12804  ,  0.34131  ,  0.33106  , -0.026678 , -0.022675 ,\n",
       "       -1.0228   ,  0.65186  , -0.14204  ,  0.29102  ,  0.56137  ,\n",
       "       -0.1294   , -0.77794  , -0.014738 , -0.0082412,  0.19769  ,\n",
       "        0.42299  ,  0.64201  ,  0.89195  ,  0.28199  ,  0.038209 ,\n",
       "       -0.066105 , -0.39848  , -0.025111 ,  0.45934  , -0.45628  ,\n",
       "        0.36668  ,  0.56928  , -0.15604  , -0.82312  , -0.46751  ,\n",
       "        0.35949  ,  0.97564  , -0.047988 , -0.47062  ,  0.65927  ,\n",
       "        0.66212  ,  0.18403  , -0.052545 , -0.63723  , -0.53374  ,\n",
       "        0.50934  , -0.55863  ,  0.011983 ,  0.096682 ,  0.053548 ,\n",
       "        0.29566  , -0.15537  , -0.40615  , -0.58044  , -0.92148  ,\n",
       "        0.61701  , -0.019925 , -0.19368  ,  0.72811  ,  0.076774 ,\n",
       "       -1.6533   , -0.6374   , -0.060303 ,  1.9839   ,  0.13529  ,\n",
       "        0.47406  , -0.1415   , -0.37578  ,  0.15041  ,  0.89496  ,\n",
       "       -0.073249 ,  0.6373   , -0.33459  ,  0.97642  , -0.41846  ,\n",
       "        0.26385  ,  0.6476   , -0.057542 ,  0.0052852,  0.31263  ,\n",
       "       -0.0048151, -0.2146   , -0.18337  , -0.50711  , -0.10764  ,\n",
       "        0.15502  ,  0.12009  , -1.0232   ,  0.55192  , -1.4446   ,\n",
       "       -0.376    ,  0.11863  , -0.70984  , -0.16651  , -0.43381  ,\n",
       "        0.27606  ,  0.58443  , -0.3868   , -0.46112  ,  0.24229  ,\n",
       "       -0.21982  , -0.2088   , -0.37728  ,  1.2899   ,  0.13223  ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model['product']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "steady-prairie",
   "metadata": {},
   "source": [
    "We then take the average to represent the string ‚Äòworst product‚Äô in the form of vectors having 100 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "smooth-control",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.11813501,  0.43936002,  0.60802996, -0.164894  , -0.3030775 ,\n",
       "       -0.60688496,  0.1605    , -0.26069   ,  0.02358   ,  0.34136   ,\n",
       "       -0.111839  , -0.583655  ,  0.139666  , -0.10315561,  0.030665  ,\n",
       "        0.49541497,  0.18870498,  0.25419003, -0.03445001,  0.45378453,\n",
       "        0.4016925 , -0.12223   ,  0.1289095 ,  0.28862   , -0.30654   ,\n",
       "       -0.14874502,  0.13900502,  0.16596499, -0.35694999, -0.43865   ,\n",
       "        0.40439   ,  0.24017   ,  0.189806  , -0.045865  ,  0.04394001,\n",
       "        0.03569499, -0.07907   , -0.20655751, -0.33227798, -0.205525  ,\n",
       "       -0.07321501,  0.055655  ,  0.1125565 ,  0.055053  ,  0.518414  ,\n",
       "        0.70503   ,  0.425865  , -0.491045  , -0.48198   , -1.00149   ,\n",
       "        0.23550001, -0.2138575 , -0.24823001,  0.806085  , -0.028318  ,\n",
       "       -1.82885   , -0.04099497,  0.23820849,  1.70775   ,  0.37519002,\n",
       "       -0.18309   ,  0.348435  , -0.638785  , -0.1862    ,  0.794515  ,\n",
       "        0.17723551,  0.45028   , -0.401385  ,  0.4831385 , -0.27663   ,\n",
       "        0.063325  ,  0.37102   , -0.44128102,  0.5663426 ,  0.272725  ,\n",
       "        0.00857595, -0.33896   , -0.10173149, -0.6172    ,  0.194975  ,\n",
       "        0.492415  ,  0.39013   , -0.85080504,  0.43901   , -1.20017   ,\n",
       "       -0.4649    , -0.35109   , -0.542085  , -0.2329    , -0.2064665 ,\n",
       "        0.375895  ,  0.66306996, -0.41600502, -0.209997  , -0.15405998,\n",
       "        0.16413002, -0.00794   , -0.064845  ,  0.75461996, -0.10377   ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model['worst'] + model['product'])/2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
